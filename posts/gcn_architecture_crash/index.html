<!DOCTYPE html>
<html lang="en">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<title>AMD GCNアーキテクチャ文書を読んでメモ - neuromantic</title>

<meta name="description" content="用語 略語 説明 VS Vertex Shader PS Pixel Shader (Fragment Shader) VLIW Very Long Instruction Word FLOPS FLoating point Operations Per Second GCN Graphics Core Next CU Compute Unit EU Export Unit ISA Instruction Set Architecture SIMD Single Instruction Multiple Data ALU Arithmetic Logic Unit AGU Address Generation Unit SALU Scalar Arithmetic Logic Unit VALU Vector Arithmetic Logic Unit APU Accelated Processing Unit PC Program Counter IB">
<meta name="keywords" content= />
<meta name="author" content="Jongmin Yun, Neu.">
<link rel="canonical" href="https://liliilli.github.io/posts/gcn_architecture_crash/" />
<link href="https://liliilli.github.io/assets/css/stylesheet.min.a3b13905fd4b98ea165a18374ae5215d9de97a04f187f789736c56858296ba12.css" integrity="sha256-o7E5Bf1LmOoWWhg3SuUhXZ3pegTxh/eJc2xWhYKWuhI=" rel="preload stylesheet"
    as="style">
<link rel="apple-touch-icon" href="https://liliilli.github.io/apple-touch-icon.png">
<link rel="icon" href="https://liliilli.github.io/favicon.ico">
<meta name="generator" content="Hugo 0.75.1" />


</head>

<body class="single" id="top">
<header class="header">
    <nav class="nav">
        <p class="logo"><a href="https://liliilli.github.io">neuromantic</a></p>
        <ul class="menu" id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://liliilli.github.io/posts/">
                    <span>
                        Posts
                    </span>
                </a>
            </li>
            <li>
                <a href="https://liliilli.github.io/archives/">
                    <span>
                        Archives
                    </span>
                </a>
            </li>
            <li>
                <a href="https://liliilli.github.io/tags/">
                    <span>
                        Tags
                    </span>
                </a>
            </li>
            <li>
                <a href="https://liliilli.github.io/series/">
                    <span>
                        Series
                    </span>
                </a>
            </li>
        </ul>
    </nav>
</header>

    <main class="main">

<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">
      AMD GCNアーキテクチャ文書を読んでメモ
    </h1>
    <div class="post-meta">
      <time>June 19, 2020</time>&nbsp;·&nbsp;Jongmin Yun, Neu.
    </div>
  </header>
  <div class="post-content"><h2 id="用語">用語</h2>
<table>
<thead>
<tr>
<th>略語</th>
<th>説明</th>
</tr>
</thead>
<tbody>
<tr>
<td>VS</td>
<td>Vertex Shader</td>
</tr>
<tr>
<td>PS</td>
<td>Pixel Shader (Fragment Shader)</td>
</tr>
<tr>
<td>VLIW</td>
<td>Very Long Instruction Word</td>
</tr>
<tr>
<td>FLOPS</td>
<td>FLoating point Operations Per Second</td>
</tr>
<tr>
<td>GCN</td>
<td>Graphics Core Next</td>
</tr>
<tr>
<td>CU</td>
<td>Compute Unit</td>
</tr>
<tr>
<td>EU</td>
<td>Export Unit</td>
</tr>
<tr>
<td>ISA</td>
<td>Instruction Set Architecture</td>
</tr>
<tr>
<td>SIMD</td>
<td>Single Instruction Multiple Data</td>
</tr>
<tr>
<td>ALU</td>
<td>Arithmetic Logic Unit</td>
</tr>
<tr>
<td>AGU</td>
<td>Address Generation Unit</td>
</tr>
<tr>
<td>SALU</td>
<td>Scalar Arithmetic Logic Unit</td>
</tr>
<tr>
<td>VALU</td>
<td>Vector Arithmetic Logic Unit</td>
</tr>
<tr>
<td>APU</td>
<td>Accelated Processing Unit</td>
</tr>
<tr>
<td>PC</td>
<td>Program Counter</td>
</tr>
<tr>
<td>IB</td>
<td>Instruction Buffer</td>
</tr>
<tr>
<td>LRU</td>
<td>Least Recently Used</td>
</tr>
<tr>
<td>VGRP</td>
<td>Vector General Purpose Register</td>
</tr>
<tr>
<td>LDS</td>
<td>Local Data Share</td>
</tr>
<tr>
<td>GDS</td>
<td>Global Data Share</td>
</tr>
<tr>
<td>TMU</td>
<td>Texture Mapping Unit</td>
</tr>
<tr>
<td>TLB</td>
<td>Translation Lookaside Buffer</td>
</tr>
<tr>
<td>HSA</td>
<td>Heterogeneous System Architecture</td>
</tr>
<tr>
<td>DMA</td>
<td>Direct Memory Access</td>
</tr>
<tr>
<td>IOMMU</td>
<td>I/O MMU (I/O Memory Management Unit)</td>
</tr>
<tr>
<td>ACE</td>
<td>Asynchronous Compute Engines</td>
</tr>
</tbody>
</table>
<h2 id="本文-amd-graphics-cores-next-white-paper">本文 (AMD GRAPHICS CORES NEXT White Paper)</h2>
<p>p2）最初は完全な固定関数として使うようにデザインされたが、時間が経ってVSとPSの登場、そしてAMDでは並列処理を効率化させるためVLIW5とVLIW4構造のデザインを開発し性能を上げてきた。</p>
<p>これで2013年まで出た最高級グラボのTFLOPSは4TFLOPS（テラFLOPS）を超えて、モバイルも1TFLOPSを超えるようになる。</p>
<p>VLIW4デザインから一新されたGCNはCUのデザインを変えて性能を向上をした。</p>
<h3 id="compute-unit-overview">Compute Unit Overview</h3>
<p>p3）CUはGCNアーキテクチャでの基本的な演算ブロックだ。以前に使っていたISAも新しくされて、コンパイラそして開発者にもわかりやすい形となり、性能の安定性を確保している。</p>
<p>GCN以前のVLIWシリーズのシェーダー配列は複数のSIMDエンジンとして構成され、また各SIMDエンジンは16個のALUで構成されていた。各ALUは4、5個の独立した命令をVLIWに入れてまとめた形で処理することが出来た。（前はVLIW-4、後はVLIW-5）各SIMDエンジンはWavefrontという、64個の命令処理ができるもの（作業スレッド）を持ち、同時に1個のWavefrontを実行することが出来る。このデザインは特定したパイプラインでは高効率で動くが、ピクセルのフォーマットが多様化されて、またパイプラインが複雑になるにつれそれぞれ独立されて並列に実行できる命令をVLIWに組むことが難しくなって効率を上げにくくなった。</p>
<p>GCNでは各CUが4個の分離された頂点処理のためのSIMDを持って、各SIMDは同一な命令を処理する16個の作業スレッドを持っている。ただ、前のデザインみたいにまとまって1個のWavefrontになるのではなく、それぞれ別のWavefrontになれる。なのでもっと並列化が出来る。</p>
<p>効率化のためにGCNの各SIMDたちは<code>private</code>と<code>shared</code>のリソースを持ったり、共有している。命令バッファリング（Instruction Buffering）、VALUとレジスタなどはPrivateとして各SIMDに内蔵されている。Front-End、分岐ユニット、データキャッシュはSIMDの間で共有されている。</p>
<p>p4）GCNのCUの画像があるのでよく見ること。</p>
<p>またGCNで改善されたものは、メモリのCoherent Cachingがサポートされたことだ。GCNが登場づするまでGPUはメモリのCoherent（一貫性）を管理しない（すなわち外部メモリ変更による更新をしない）読み取り専用のキャッシュに依存しなければならなかった。なのでGPU中で複数のコアがやり取りをするためには、プログラマまたはコンパイラが明示的に同期化をしなければならなかった。デザイン的には簡単になるが、共有しているデータの同期化による性能低下があったのである。GCNは最初から汎用データがコア間共有されながら処理されることを念頭に置きながらデザインされた。そのためのCache Coherency ProtocolはGPUのL2キャッシュを通してデータを更新するようにし、性能向上と電力消費量の低下をした。</p>
<p>Coherencyと同時にGCNは仮想メモリも導入した。この仮想メモリはx86アーキテクチャをサポートする。これでCPUとGPUの間でデータを共有することが簡略化され、そして一つのポインターアドレスでCPUとGPUが参照出来るようになったそうだ。これでAMDのAPUでも効率の向上をしたらしい。</p>
<h3 id="cu-front-end">CU Front-End</h3>
<p>p5）GCNの各SIMDは40-bitのPCと、10Wavefront分のIBを持つ。というとCUは4個のSIMDを持つのでIBだけで40Wavefrontsを持つことになる。そしてGCNは32個のCUを持つため、最終的には同時に81,920個の作業スレッドが働くことになる。</p>
<p>4個までのCUが一つの組になり、32KBの4-way associativeのL1命令キャッシュとL2キャッシュを共有している。<em>[3]を見ること</em> キャッシュラインはx86と同じく64Bytesで、64bitsの命令を8個収めることが出来る。キャッシュが全部埋まったら、LRUによって新しい命令が入ることになる。</p>
<p>L1の命令キャッシュは4個のBankを持ち[4]、4個のCUに対して32Bytesの命令読出し（Fetch）を維持することが出来る。ただ、命令読出しは世代（age）、スケジューリングの優先順位、WaveのIBの活用によってSIMDたちの中で無作為にされる。</p>
<p>命令がWavefrontのバッファたちの中で発行されると、CUはRound-robin方式で4個のSIMDから一つを選び、10個のWavefrontから5個までの命令をEUへ実行するようにする。ただ<code>NOP</code>のような特殊な命令は他のユニットに任せることなくWavefrontから直接命令処理をする。また、CUはバリア命令を追跡するため16個のバッファリングを維持することができ、これによってWavefrontをSynchronizeさせる。</p>
<p>CUの末端部（Front-end）は「分岐（Branch）、SALU、VALU、スカラメモリ、ベクトルメモリ、そしてローカルデータシェアー、グローバルデータシェアー」の命令を処理する。しかし命令実行パイプラインに多くのSIMDが取り付くことを防ぐため、SIMDごとに同時に各タイプの一つの命令しか発行できないようになっている。また、命令順に実行するようにするため、各命令は違うWavefrontから発行されるようになっている。</p>
<p>CUは1サイクルに5個までの命令を、2つのレジスタファイル（Register File）を使って、6個までのベクトル演算装置とスカラ演算装置へ実行できる。VALUは汎用目的のグラフィック、またはコンピューター処理のために適合していて、SALUは分岐処理に適合している。</p>
<h3 id="scalar-execution-and-control-flow">Scalar Execution and Control Flow</h3>
<p>GCNで新しく実装されたスカラ（Scalar）パイプラインは、性能と電力効率で必須的な存在となっている。特に分岐処理をすることによって、GPUで分岐しょりをすることによる遅延などを防ぎ、性能低下をある程度防止する。</p>
<p>各CUは8KBのスカラレジスタファイル（Scalar Register File）を持ち、各SIMDが使えるために512個のブロックとして分かれている。また、スカラレジスタはSIMDの10個のWavefrontで共有される。Wavefrontはシステムの状態を保持する一部分を除き、112個のレジスタが割当できる。これをユーザーレジスタ（User Register）という。</p>
<p>レジスタは普段は32-bitsの値を保持できるが、連続で使ったら64-bitsまでの値を保持できる。例えば比較分岐をする時、比較した際の結果ビットをwavefrontの64個分更新するためには64-bitsのレジスタ（2個分）に必要となる。</p>
<p>1つ目でスカラパイプラインは16-bitsのオフセットを使って分岐（Conditional Branch）をハンドルしている。また、インターラプトと特定タイプの同期化をする時にも使われている。インターラプトはブレークポイントを貼ってデバッグをする際に使える新しい機能だ。</p>
<p>p6）2つ目ではAGUの役割<code>[5]</code>も果たしている。GCNのALUは64-bitsの長さを持つが、これで分岐処理によるジャンプ、関数呼び出しとリターンがもっとしやすくなっている。AGUによって移動する命令アドレスはPCで切り替わるかそれに値する処理がされている。</p>
<p>また分岐予測もSALUによって管理される。</p>
<p>スカラのL1キャッシュは読み取り専用だ。SALUが使われている所って大体分岐処理であるため、メモリに何かを書く状況がないためだ。このL1キャッシュは命令L1メモリキャッシュとほぼ構造が同じで、16KBのキャッシュは同様に4-way associativeであって、LRUアルゴリズムと64Bytesのラインを持つ。また4個のCUによって共有されて、L2キャッシュがあることも同じだ。そして各CUで1サイクルに16BytesのThroughputを持つ。</p>
<h3 id="vector-execution">Vector Execution</h3>
<p>既存のVLIWは一つのSIMDを持ち、その中に独立で演算される命令が組み込まれて実行される仕組みになっている。しかしこの構造はコンパイラがどのぐらいコードから生み出される命令を並行にばら撒いて実行させるようにするかによって性能が大きく違うことと、コード自体が並列化されにくいとしたら絶対的に性能が落ちることになる短所がある。</p>
<p>GDNアーキテクチャはWavefrontから予測できない並列化を避けるようにし、ちょうど良いぐらいの並列化をドライバーなどがやるようにして、性能の安定性を追求する。こうすることで汎用目的の処理でも性能が劣ることがあんまりなくなった。</p>
<h3 id="vector-registers">Vector Registers</h3>
<p>ベクトル演算のためのレジスタも4つの独立されたブロックに分かれている。以前のVLIW構造では一つのSIMDにあらゆる命令がまざって入るため、どでかく効率が悪いレジスタにしなければならなかった。</p>
<p>VGRPsは32-bits長さの64個のレーンを持つ。隣接したVGRPsは64ビットまたは128ビットに相当する値を構成されるために使えることもある。各SIMDはVGRPsのために64KBのパーティションを提供しているので、CU1個のVGRPsの数は同一である。（256個のVGRPs組が存在して、一つは32-bits＊64＝256Bytes？）</p>
<h3 id="vector-alus">Vector ALUs</h3>
<p>p7）各SIMDは16個のレーンで構成され、IEEE-754単精度浮動小数点数と倍精度浮動小数点数を支援する。また、性能低下の無いdenormals（アンダーフローされる浮動小数点の数前の数）などもサポートする。SIMDの各レーンは24-bitの整数演算、また単精度の積和演算・融合積和演算<code>[6]</code>（fused multiply-add）ができる。積和演算は<code>MAD</code>のような形として、<code>a := b * c + a</code>になる。融合積和とは、<code>b * c</code>をする時浮動小数点の値を丸めずに1命令で行い誤差をへらすことだ。</p>
<p>24-bitsの整数のMAD演算は作業グループの中でアドレスを演算する時に有用に使われる。一つのSIMDの64個の作業スレッドがVALUの演算を行うには4 Cyclesがかかる。</p>
<p>GCNは<code>SAD</code>と<code>quad-SAD</code>を追加し<code>[7]</code>、映像または画像処理の性能を向上しようとした。SADは画像がどれだけ似ているかを検出する時に使われるアルゴリズムで、画像の中で異なるブロックの中の互いのピクセルの絶対差を求め最後に全部合わせて似ているかの指標として使う。またRGBA 8-Bitsの色が入った画像でもSADが出来るようにquad-SADを追加した。</p>
<p>これを使ってCUはクロックごとに256個のピクセルの処理ができた。こういったものはビデオ検索、または動作認識などに使われるそうだ。</p>
<p>倍精度と32-Bitsの整数処理は処理効率が劣る。倍精度浮動小数点の場合、単精度より1/2から1/16まで性能が落ちる可能性がある。またドライバーなどのサポートによって性能が違うかもしれない。</p>
<h3 id="local-data-share--atomics">Local Data Share &amp; Atomics</h3>
<p>LDSというメモリ領域はグラフィックレンダリングでの補完または作業グループ（Work-group）の同期化のためにほぼ第3のRegister Fileとして扱わなければならない。（重要）GCNのLDSは16または32個のBanksを持って、64KBに拡張された。各Bankは32-Bits長さのエントリーが512個並んでいる。</p>
<p>LDSの用途としてレンダリングの方ではテクスチャーデータの補完などに使われる。その時に同時データ接近による衝突は起こらない。Compute Shaderの場合にはWork-Groupsの中で共有されたデータなどを読み込んだり書き込んだりする時にLDSが使われる。これによってデータの接近によるキャッシュの汚染が避けるようになった。</p>
<h3 id="export">Export</h3>
<p>EUはCUからGDS（Global Data Share）そして固定関数のグラフィックHWへの窓口だ。CUで演算が終わった時、一般的に結果はグラフィックパイプラインのほかのユニットへ転送される。EUはプログラミング可能なステージから得た結果をテセレーションまたはRasterization、Back-endなどに書き込む役割をする。</p>
<p>GDSはLDSとは基本的には同じものだが、全体CUが共有しているのですべてのWavefrontの間の同期化を制御する。</p>
<h3 id="vertor-memory">Vertor Memory</h3>
<p>各CUの各SIMDsは1クロックに128個の単精度浮動小数点数の演算が出来る。既存のVLIW-4からGCNに移行してキャッシュの構造で一番変わったのはグラフィック描画に特化されたデザインから汎用レンダリングまたはx86のプロセッサーと互換ができるようプログラミングな構造になったことだ。代表的なものがCUで、GCN全般のシステムまで拡張している。</p>
<p>p9）Figure 5を見ること。</p>
<p>上にもあったが、L1データキャッシュは16KB、4-way associative、64Bytesライン、そしてLRUアルゴリズムを持つ。またL2データそして他のキャッシュとのデータと同じ（Coherent）データ内容を持つ。</p>
<p>データL1（L1D）はDirtyマスクがついた「Write-through」<code>[8]</code>（メモリとキャッシュへの書き込みが同時に終わる）そして「Write-allocate」（Write-missの際に下のデータブロックが上のキャッシュにOverwrite）を採択している。~（＋ということは実際にはWrite-throughではなく、Write-backなのでは…？）~<code>[9]</code>64Wavefrontに該当するキャッシュラインは命令が終わるとL2へOverwriteされる。またL1のキャッシュラインがDirtyかではないかによってL2へ放出されるかないかが分かれる。</p>
<p>AGU（Address Generation Unit）が連続したアドレス（0x0, 0x4, 0x8…）を計算したらデータL1のキャッシュタグ（Cache-Tag）をたどる。それでCache hitが発生したら64Bytesのラインを全部読み取る。もしデータがすべて連続されていて一つのキャッシュラインに収まることが出来たら（With fully coalesced requests,）実際使ってるWavefrontは1/4ぐらいになる。読まれたキャッシュラインはvGRPsかLDSに保存される。</p>
<p>L1データへの書き込みはちょっと複雑で、データ自体が適切なフォーマットに変換しなければならないし、また書き込むアドレスもL1キャッシュへのHit、L2キャッシュへまで書き込むために癒合（Coalesced）される必要があるそうだ。もしCache missが発生したらL2それともそれに準ずるメモリでブロックを探す。</p>
<p>効率を上げるためにグラフィックレンダリングではある構造を再使用（？）している。まずAGUは1サイクルに4個のテクスチャアドレスを受け取り、nearest neighborsで16個のサンプリングアドレスを返す。このサンプリングアドレスがL1データに接近し読み取ったデータをTMUから圧縮開放する。そしてフィルターによってフォーマットに合わせた4個の補完されたテクセルがベクトルのRegister Fileに保存される。</p>
<h3 id="l2-cachecoherency-and-memory">L2 Cache、Coherency and Memory</h3>
<p>p10）L2キャッシュはGCNGPUのcoherencyを維持する中核だ。L2キャッシュはCUまたはCUたちの間で共有されているL1命令とデータ、そしてスカラキャッシュのbackstop（補助？盗み取り？）役をしている。L2キャッシュはいくつかのブロックなどに分離されて、CUからCrossbarを通してメモリへアクセスされるようになっている。</p>
<blockquote>
<p>Figure 6を見ること。</p>
</blockquote>
<p>L1と同様にL2も仮想アドレスをサポートしているのでTLBは要らない。（なんかVirtualだとしたらPhysicalに変換するためにTLBが要るかもと思ったらそうでもなかった…）<code>[11]</code> そしてL2は16-way associativeでL1と同じく64Bytesキャッシュライン、LRUアルゴリズムを持つ。しかしL1とは違ってここでは「Write-Back」「Write-Allocate」ポリシーを使う。小さく小分けされたL2メモリブロックは64~128KBの空間を持つ。</p>
<p>L2キャッシュがCoherentすることにより、それぞれ違うWavefrontの間の同期化またはアトミック操作（Atomic Operation）が実行できるように適合な場になった。もちろんWavefrontの中のみならLDSだけでアトミック操作することが可能である。しかし違うWavefrontの間に同期化をすべきならL2キャッシュを使わなければならない。L2スライスは1サイクル、1キャッシュラインに16個のアトミック操作をする事ができる。</p>
<p>理論上ではL1データは作業グループの中でのメモリ一貫性を保つ。Wavefrontが開放される時、または同期化のためのバリアーが解かれた時データがL2にかかれてWavefront間のL2メモリ一貫性が維持される。</p>
<p>またこのキャッシュ構造はx86のマイクロプロセッサーと互換するようにデザインされた。GCN仮想メモリシステムはx86アドレス空間のための基本ページ単位である4KBのページをサポートしている。またキャッシュラインが64Bytesであることもx86のプロセッサーと互換するためだそうだ。</p>
<p>メモリコントローラーは64-Bits長さで2つの独立したGDDR5またはDDR3の32-Bitsメモリチャンネルで構成されている。</p>
<h3 id="programming-model">Programming Model</h3>
<p>p11）GCNの新しいISAはHSAを基にしている。HSAとはハードウェアに拘らないアーキテクチャとして（決まった仕様はあるので完全独立ではない）CPUとGPUがコミュニケーションする仕様だ。HSAはHSAIL（Intermediate Language）というバーチャルISAを使って最終的にはHWの機械語にコンパイルするようにしている。<code>[12]</code></p>
<h3 id="system-architecture">System Architecture</h3>
<p>GCNは双方向のDMAエンジンを搭載し、PCI Express™ 3.0を使ってデータを双方向に転送することが出来る。またGCNはIOMMUを搭載し、x86のアドレスをGPUへマッピングすること簡単に出来る。ということはGCNのDMAエンジンはGPUとCPUのメモリページへの接近が追加オーバーヘッドなしで行われる。</p>
<p>GCNのCommand Processorはドライバーから高級言語のAPIを読み取り、各パイプラインへマッピングする役割を持っている。GCNでは主に2つのパイプラインで構成されている。一つはACEと呼ばれるもので、Compute Shaderを管理している。Graphics Command Processorは従来のシェーダーと固定関数を管理する。ACEとGCPは一緒に各シェーダーステージのためのCommand Streamを持ち、GCN仕様のHWでマルチタスキングを行う。</p>
<p>そのマルチタスキングのためにGCNでは仮想メモリが実装された。ということでGPUのVRAMの中で複数のアプリケーションのメモリが安全に共存できる。</p>
<p>ACEsはCompute Shaderに対してスケジューリングとリソースの割当を担当する。各ACEはキャッシュまたはメモリからコマンとを持ってきて、スケジューリングのためのTask queueを形成する。各タスク（Task）は優先順位を持っており、ドライバーからそれらを制御している。</p>
<p>各サイクルでACEは作業グループと一つのWavefrontを作り依存性が無い限り無作為に動作する。</p>
<p>またACEsは普通はそれぞれ独立に動くが、64KB~128KBのGDS、メモリまたはキャッシュ接近によって同期化されることがある。それにより各ACEsはTask Graphを形成し、お互いに依存性を持つようになる。なので実際にはACEsはグラフィックスパイプラインの特定ステージ、それとも他のACEに依存されるかするようになり、途中で止まったり違うTask queueの依存性を持たないACEが動いたりする。</p>
<h3 id="graphics-architecture">Graphics Architecture</h3>
<p>Graphics Command Processorは従来のグラフィックスパイプラインを構想している。GCNのピクセルパイプラインはスクリーン空間を分割して独立したタイルとしてレンダリングする。各ラスタライザは1サイクルに一つの三角形を分析し、最大16ピクセルを生み出す。</p>
<p>またGCNでは各グラフィックパイプラインは並列に動く。これはACEsと同じであるし、すなわち依存性も生まれる。</p>
<h2 id="参照">参照</h2>
<p><a href="https://www.techpowerup.com/gpu-specs/docs/amd-gcn1-architecture.pdf">AMD GRAPHICS CORES NEXT White Paper</a></p>
<p><a href="https://www.slideshare.net/DevCentralAMD/gs4106-the-amd-gcn-architecture-a-crash-course-by-layla-mah">GS-4106 The AMD GCN Architecture - A Crash Course, by Layla Mah</a></p>
<p><a href="http://csillustrated.berkeley.edu/PDFs/handouts/cache-3-associativity-handout.pdf">[3] Cache Associativity</a></p>
<p><a href="https://en.wikipedia.org/wiki/Memory_bank">[4] Memory Bank</a></p>
<p><a href="https://en.wikipedia.org/wiki/Address_generation_unit">[5] Address Generation Unit</a></p>
<p><a href="%5Bhttps://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation#Fused_multiply%E2%80%93add%5D(https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation#Fused_multiply%E2%80%93add)">[6] Multiply-accumulate operation</a></p>
<p><a href="https://www.google.com/search?q=sum+of+absolute+difference&amp;oq=sum+of+absol&amp;aqs=chrome.0.0j69i57j0l6.2572j0j4&amp;sourceid=chrome&amp;ie=UTF-8">[7] Sum of absolute difference</a></p>
<p><a href="https://en.wikipedia.org/wiki/Cache_(computing)">[8] Cache_(Computing) Writing policies</a></p>
<p><a href="http://web.cs.iastate.edu/~prabhu/Tutorial/CACHE/interac.html">[9] Interaction Policies with Main Memory</a></p>
<p><a href="https://stackoverflow.com/questions/5041328/in-cuda-what-is-memory-coalescing-and-how-is-it-achieved">[10] In CUDA, what is memory coalescing, and how is it achieved?</a></p>
<p><a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer">[11] Translation Lookaside Buffer</a></p>
<p><a href="https://pc.watch.impress.co.jp/docs/column/kaigai/547768.html">[12] AMD GPUとモバイルGPUにで同じプログラムを走らせるHSA構想</a></p>
</div>
  <footer class="post-footer">
  </footer>
</article>
    </main><footer class="footer">
    <span>&copy; 2020 <a href="https://liliilli.github.io">neuromantic</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo️️</a>️</span>
    <span>&middot;</span>
    <span>Theme️ <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top">
    <button class="top-link" id="top-link" type="button">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6">
            <path d="M12 6H0l6-6z" /></svg>
    </button>
</a>
<script src="https://liliilli.github.io/assets/js/highlight.min.e7afc2928c0925d65c4732dfebe147014d91299a98e819e4b42f25c4fa68e91c.js" integrity="sha256-56/CkowJJdZcRzLf6&#43;FHAU2RKZqY6BnktC8lxPpo6Rw="></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();

            document.querySelector(this.getAttribute("href")).scrollIntoView({
                behavior: "smooth"
            });
        });
    });
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }
</script>
</body>

</html>