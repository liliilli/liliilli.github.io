<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AMD GCNアーキテクチャ文書を読んでメモ | neuromantic</title><meta name=keywords content><meta name=description content="用語 略語 説明 VS Vertex Shader PS Pixel Shader (Fragment Shader) VLIW Very Long Instruction Word FLOPS FLoating point Operations Per Second GCN Graphics Core Next CU Compute Unit EU Export Unit ISA Instruction Set Architecture SIMD Single Instruction Multiple Data ALU Arithmetic Logic Unit AGU Address Generation Unit SALU Scalar Arithmetic Logic Unit VALU Vector Arithmetic Logic Unit APU Accelated Processing Unit PC Program Counter IB"><meta name=author content="Jongmin Yun, Neu."><link rel=canonical href=https://liliilli.github.io/posts/gcn_architecture_crash/><link crossorigin=anonymous href=/assets/css/stylesheet.min.bc435bed1061be2618667408894ae8a5d27c970831ce57f287e42f911918fcbc.css integrity="sha256-vENb7RBhviYYZnQIiUropdJ8lwgxzlfyh+QvkRkY/Lw=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://liliilli.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://liliilli.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://liliilli.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://liliilli.github.io/apple-touch-icon.png><link rel=mask-icon href=https://liliilli.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.82.0"><meta property="og:title" content="AMD GCNアーキテクチャ文書を読んでメモ"><meta property="og:description" content="用語 略語 説明 VS Vertex Shader PS Pixel Shader (Fragment Shader) VLIW Very Long Instruction Word FLOPS FLoating point Operations Per Second GCN Graphics Core Next CU Compute Unit EU Export Unit ISA Instruction Set Architecture SIMD Single Instruction Multiple Data ALU Arithmetic Logic Unit AGU Address Generation Unit SALU Scalar Arithmetic Logic Unit VALU Vector Arithmetic Logic Unit APU Accelated Processing Unit PC Program Counter IB"><meta property="og:type" content="article"><meta property="og:url" content="https://liliilli.github.io/posts/gcn_architecture_crash/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-19T12:16:09+09:00"><meta property="article:modified_time" content="2020-06-23T08:42:00+09:00"><meta property="og:site_name" content="neuromantic"><meta name=twitter:card content="summary"><meta name=twitter:title content="AMD GCNアーキテクチャ文書を読んでメモ"><meta name=twitter:description content="用語 略語 説明 VS Vertex Shader PS Pixel Shader (Fragment Shader) VLIW Very Long Instruction Word FLOPS FLoating point Operations Per Second GCN Graphics Core Next CU Compute Unit EU Export Unit ISA Instruction Set Architecture SIMD Single Instruction Multiple Data ALU Arithmetic Logic Unit AGU Address Generation Unit SALU Scalar Arithmetic Logic Unit VALU Vector Arithmetic Logic Unit APU Accelated Processing Unit PC Program Counter IB"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://liliilli.github.io/posts/"},{"@type":"ListItem","position":3,"name":"AMD GCNアーキテクチャ文書を読んでメモ","item":"https://liliilli.github.io/posts/gcn_architecture_crash/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AMD GCNアーキテクチャ文書を読んでメモ","name":"AMD GCNアーキテクチャ文書を読んでメモ","description":"用語 略語 説明 VS Vertex Shader PS Pixel Shader (Fragment Shader) VLIW Very Long Instruction Word FLOPS FLoating point Operations Per Second GCN Graphics Core Next CU Compute Unit EU Export Unit ISA Instruction Set Architecture SIMD Single Instruction Multiple Data ALU Arithmetic Logic Unit AGU Address Generation Unit SALU Scalar Arithmetic Logic Unit VALU Vector Arithmetic Logic Unit APU Accelated Processing Unit PC Program Counter IB","keywords":[],"articleBody":"用語    略語 説明     VS Vertex Shader   PS Pixel Shader (Fragment Shader)   VLIW Very Long Instruction Word   FLOPS FLoating point Operations Per Second   GCN Graphics Core Next   CU Compute Unit   EU Export Unit   ISA Instruction Set Architecture   SIMD Single Instruction Multiple Data   ALU Arithmetic Logic Unit   AGU Address Generation Unit   SALU Scalar Arithmetic Logic Unit   VALU Vector Arithmetic Logic Unit   APU Accelated Processing Unit   PC Program Counter   IB Instruction Buffer   LRU Least Recently Used   VGRP Vector General Purpose Register   LDS Local Data Share   GDS Global Data Share   TMU Texture Mapping Unit   TLB Translation Lookaside Buffer   HSA Heterogeneous System Architecture   DMA Direct Memory Access   IOMMU I/O MMU (I/O Memory Management Unit)   ACE Asynchronous Compute Engines    本文 (AMD GRAPHICS CORES NEXT White Paper) p2）最初は完全な固定関数として使うようにデザインされたが、時間が経ってVSとPSの登場、そしてAMDでは並列処理を効率化させるためVLIW5とVLIW4構造のデザインを開発し性能を上げてきた。\nこれで2013年まで出た最高級グラボのTFLOPSは4TFLOPS（テラFLOPS）を超えて、モバイルも1TFLOPSを超えるようになる。\nVLIW4デザインから一新されたGCNはCUのデザインを変えて性能を向上をした。\nCompute Unit Overview p3）CUはGCNアーキテクチャでの基本的な演算ブロックだ。以前に使っていたISAも新しくされて、コンパイラそして開発者にもわかりやすい形となり、性能の安定性を確保している。\nGCN以前のVLIWシリーズのシェーダー配列は複数のSIMDエンジンとして構成され、また各SIMDエンジンは16個のALUで構成されていた。各ALUは4、5個の独立した命令をVLIWに入れてまとめた形で処理することが出来た。（前はVLIW-4、後はVLIW-5）各SIMDエンジンはWavefrontという、64個の命令処理ができるもの（作業スレッド）を持ち、同時に1個のWavefrontを実行することが出来る。このデザインは特定したパイプラインでは高効率で動くが、ピクセルのフォーマットが多様化されて、またパイプラインが複雑になるにつれそれぞれ独立されて並列に実行できる命令をVLIWに組むことが難しくなって効率を上げにくくなった。\nGCNでは各CUが4個の分離された頂点処理のためのSIMDを持って、各SIMDは同一な命令を処理する16個の作業スレッドを持っている。ただ、前のデザインみたいにまとまって1個のWavefrontになるのではなく、それぞれ別のWavefrontになれる。なのでもっと並列化が出来る。\n効率化のためにGCNの各SIMDたちはprivateとsharedのリソースを持ったり、共有している。命令バッファリング（Instruction Buffering）、VALUとレジスタなどはPrivateとして各SIMDに内蔵されている。Front-End、分岐ユニット、データキャッシュはSIMDの間で共有されている。\np4）GCNのCUの画像があるのでよく見ること。\nまたGCNで改善されたものは、メモリのCoherent Cachingがサポートされたことだ。GCNが登場づするまでGPUはメモリのCoherent（一貫性）を管理しない（すなわち外部メモリ変更による更新をしない）読み取り専用のキャッシュに依存しなければならなかった。なのでGPU中で複数のコアがやり取りをするためには、プログラマまたはコンパイラが明示的に同期化をしなければならなかった。デザイン的には簡単になるが、共有しているデータの同期化による性能低下があったのである。GCNは最初から汎用データがコア間共有されながら処理されることを念頭に置きながらデザインされた。そのためのCache Coherency ProtocolはGPUのL2キャッシュを通してデータを更新するようにし、性能向上と電力消費量の低下をした。\nCoherencyと同時にGCNは仮想メモリも導入した。この仮想メモリはx86アーキテクチャをサポートする。これでCPUとGPUの間でデータを共有することが簡略化され、そして一つのポインターアドレスでCPUとGPUが参照出来るようになったそうだ。これでAMDのAPUでも効率の向上をしたらしい。\nCU Front-End p5）GCNの各SIMDは40-bitのPCと、10Wavefront分のIBを持つ。というとCUは4個のSIMDを持つのでIBだけで40Wavefrontsを持つことになる。そしてGCNは32個のCUを持つため、最終的には同時に81,920個の作業スレッドが働くことになる。\n4個までのCUが一つの組になり、32KBの4-way associativeのL1命令キャッシュとL2キャッシュを共有している。[3]を見ること キャッシュラインはx86と同じく64Bytesで、64bitsの命令を8個収めることが出来る。キャッシュが全部埋まったら、LRUによって新しい命令が入ることになる。\nL1の命令キャッシュは4個のBankを持ち[4]、4個のCUに対して32Bytesの命令読出し（Fetch）を維持することが出来る。ただ、命令読出しは世代（age）、スケジューリングの優先順位、WaveのIBの活用によってSIMDたちの中で無作為にされる。\n命令がWavefrontのバッファたちの中で発行されると、CUはRound-robin方式で4個のSIMDから一つを選び、10個のWavefrontから5個までの命令をEUへ実行するようにする。ただNOPのような特殊な命令は他のユニットに任せることなくWavefrontから直接命令処理をする。また、CUはバリア命令を追跡するため16個のバッファリングを維持することができ、これによってWavefrontをSynchronizeさせる。\nCUの末端部（Front-end）は「分岐（Branch）、SALU、VALU、スカラメモリ、ベクトルメモリ、そしてローカルデータシェアー、グローバルデータシェアー」の命令を処理する。しかし命令実行パイプラインに多くのSIMDが取り付くことを防ぐため、SIMDごとに同時に各タイプの一つの命令しか発行できないようになっている。また、命令順に実行するようにするため、各命令は違うWavefrontから発行されるようになっている。\nCUは1サイクルに5個までの命令を、2つのレジスタファイル（Register File）を使って、6個までのベクトル演算装置とスカラ演算装置へ実行できる。VALUは汎用目的のグラフィック、またはコンピューター処理のために適合していて、SALUは分岐処理に適合している。\nScalar Execution and Control Flow GCNで新しく実装されたスカラ（Scalar）パイプラインは、性能と電力効率で必須的な存在となっている。特に分岐処理をすることによって、GPUで分岐しょりをすることによる遅延などを防ぎ、性能低下をある程度防止する。\n各CUは8KBのスカラレジスタファイル（Scalar Register File）を持ち、各SIMDが使えるために512個のブロックとして分かれている。また、スカラレジスタはSIMDの10個のWavefrontで共有される。Wavefrontはシステムの状態を保持する一部分を除き、112個のレジスタが割当できる。これをユーザーレジスタ（User Register）という。\nレジスタは普段は32-bitsの値を保持できるが、連続で使ったら64-bitsまでの値を保持できる。例えば比較分岐をする時、比較した際の結果ビットをwavefrontの64個分更新するためには64-bitsのレジスタ（2個分）に必要となる。\n1つ目でスカラパイプラインは16-bitsのオフセットを使って分岐（Conditional Branch）をハンドルしている。また、インターラプトと特定タイプの同期化をする時にも使われている。インターラプトはブレークポイントを貼ってデバッグをする際に使える新しい機能だ。\np6）2つ目ではAGUの役割[5]も果たしている。GCNのALUは64-bitsの長さを持つが、これで分岐処理によるジャンプ、関数呼び出しとリターンがもっとしやすくなっている。AGUによって移動する命令アドレスはPCで切り替わるかそれに値する処理がされている。\nまた分岐予測もSALUによって管理される。\nスカラのL1キャッシュは読み取り専用だ。SALUが使われている所って大体分岐処理であるため、メモリに何かを書く状況がないためだ。このL1キャッシュは命令L1メモリキャッシュとほぼ構造が同じで、16KBのキャッシュは同様に4-way associativeであって、LRUアルゴリズムと64Bytesのラインを持つ。また4個のCUによって共有されて、L2キャッシュがあることも同じだ。そして各CUで1サイクルに16BytesのThroughputを持つ。\nVector Execution 既存のVLIWは一つのSIMDを持ち、その中に独立で演算される命令が組み込まれて実行される仕組みになっている。しかしこの構造はコンパイラがどのぐらいコードから生み出される命令を並行にばら撒いて実行させるようにするかによって性能が大きく違うことと、コード自体が並列化されにくいとしたら絶対的に性能が落ちることになる短所がある。\nGDNアーキテクチャはWavefrontから予測できない並列化を避けるようにし、ちょうど良いぐらいの並列化をドライバーなどがやるようにして、性能の安定性を追求する。こうすることで汎用目的の処理でも性能が劣ることがあんまりなくなった。\nVector Registers ベクトル演算のためのレジスタも4つの独立されたブロックに分かれている。以前のVLIW構造では一つのSIMDにあらゆる命令がまざって入るため、どでかく効率が悪いレジスタにしなければならなかった。\nVGRPsは32-bits長さの64個のレーンを持つ。隣接したVGRPsは64ビットまたは128ビットに相当する値を構成されるために使えることもある。各SIMDはVGRPsのために64KBのパーティションを提供しているので、CU1個のVGRPsの数は同一である。（256個のVGRPs組が存在して、一つは32-bits＊64＝256Bytes？）\nVector ALUs p7）各SIMDは16個のレーンで構成され、IEEE-754単精度浮動小数点数と倍精度浮動小数点数を支援する。また、性能低下の無いdenormals（アンダーフローされる浮動小数点の数前の数）などもサポートする。SIMDの各レーンは24-bitの整数演算、また単精度の積和演算・融合積和演算[6]（fused multiply-add）ができる。積和演算はMADのような形として、a := b * c + aになる。融合積和とは、b * cをする時浮動小数点の値を丸めずに1命令で行い誤差をへらすことだ。\n24-bitsの整数のMAD演算は作業グループの中でアドレスを演算する時に有用に使われる。一つのSIMDの64個の作業スレッドがVALUの演算を行うには4 Cyclesがかかる。\nGCNはSADとquad-SADを追加し[7]、映像または画像処理の性能を向上しようとした。SADは画像がどれだけ似ているかを検出する時に使われるアルゴリズムで、画像の中で異なるブロックの中の互いのピクセルの絶対差を求め最後に全部合わせて似ているかの指標として使う。またRGBA 8-Bitsの色が入った画像でもSADが出来るようにquad-SADを追加した。\nこれを使ってCUはクロックごとに256個のピクセルの処理ができた。こういったものはビデオ検索、または動作認識などに使われるそうだ。\n倍精度と32-Bitsの整数処理は処理効率が劣る。倍精度浮動小数点の場合、単精度より1/2から1/16まで性能が落ちる可能性がある。またドライバーなどのサポートによって性能が違うかもしれない。\nLocal Data Share \u0026 Atomics LDSというメモリ領域はグラフィックレンダリングでの補完または作業グループ（Work-group）の同期化のためにほぼ第3のRegister Fileとして扱わなければならない。（重要）GCNのLDSは16または32個のBanksを持って、64KBに拡張された。各Bankは32-Bits長さのエントリーが512個並んでいる。\nLDSの用途としてレンダリングの方ではテクスチャーデータの補完などに使われる。その時に同時データ接近による衝突は起こらない。Compute Shaderの場合にはWork-Groupsの中で共有されたデータなどを読み込んだり書き込んだりする時にLDSが使われる。これによってデータの接近によるキャッシュの汚染が避けるようになった。\nExport EUはCUからGDS（Global Data Share）そして固定関数のグラフィックHWへの窓口だ。CUで演算が終わった時、一般的に結果はグラフィックパイプラインのほかのユニットへ転送される。EUはプログラミング可能なステージから得た結果をテセレーションまたはRasterization、Back-endなどに書き込む役割をする。\nGDSはLDSとは基本的には同じものだが、全体CUが共有しているのですべてのWavefrontの間の同期化を制御する。\nVertor Memory 各CUの各SIMDsは1クロックに128個の単精度浮動小数点数の演算が出来る。既存のVLIW-4からGCNに移行してキャッシュの構造で一番変わったのはグラフィック描画に特化されたデザインから汎用レンダリングまたはx86のプロセッサーと互換ができるようプログラミングな構造になったことだ。代表的なものがCUで、GCN全般のシステムまで拡張している。\np9）Figure 5を見ること。\n上にもあったが、L1データキャッシュは16KB、4-way associative、64Bytesライン、そしてLRUアルゴリズムを持つ。またL2データそして他のキャッシュとのデータと同じ（Coherent）データ内容を持つ。\nデータL1（L1D）はDirtyマスクがついた「Write-through」[8]（メモリとキャッシュへの書き込みが同時に終わる）そして「Write-allocate」（Write-missの際に下のデータブロックが上のキャッシュにOverwrite）を採択している。~（＋ということは実際にはWrite-throughではなく、Write-backなのでは…？）~[9]64Wavefrontに該当するキャッシュラインは命令が終わるとL2へOverwriteされる。またL1のキャッシュラインがDirtyかではないかによってL2へ放出されるかないかが分かれる。\nAGU（Address Generation Unit）が連続したアドレス（0x0, 0x4, 0x8…）を計算したらデータL1のキャッシュタグ（Cache-Tag）をたどる。それでCache hitが発生したら64Bytesのラインを全部読み取る。もしデータがすべて連続されていて一つのキャッシュラインに収まることが出来たら（With fully coalesced requests,）実際使ってるWavefrontは1/4ぐらいになる。読まれたキャッシュラインはvGRPsかLDSに保存される。\nL1データへの書き込みはちょっと複雑で、データ自体が適切なフォーマットに変換しなければならないし、また書き込むアドレスもL1キャッシュへのHit、L2キャッシュへまで書き込むために癒合（Coalesced）される必要があるそうだ。もしCache missが発生したらL2それともそれに準ずるメモリでブロックを探す。\n効率を上げるためにグラフィックレンダリングではある構造を再使用（？）している。まずAGUは1サイクルに4個のテクスチャアドレスを受け取り、nearest neighborsで16個のサンプリングアドレスを返す。このサンプリングアドレスがL1データに接近し読み取ったデータをTMUから圧縮開放する。そしてフィルターによってフォーマットに合わせた4個の補完されたテクセルがベクトルのRegister Fileに保存される。\nL2 Cache、Coherency and Memory p10）L2キャッシュはGCNGPUのcoherencyを維持する中核だ。L2キャッシュはCUまたはCUたちの間で共有されているL1命令とデータ、そしてスカラキャッシュのbackstop（補助？盗み取り？）役をしている。L2キャッシュはいくつかのブロックなどに分離されて、CUからCrossbarを通してメモリへアクセスされるようになっている。\n Figure 6を見ること。\n L1と同様にL2も仮想アドレスをサポートしているのでTLBは要らない。（なんかVirtualだとしたらPhysicalに変換するためにTLBが要るかもと思ったらそうでもなかった…）[11] そしてL2は16-way associativeでL1と同じく64Bytesキャッシュライン、LRUアルゴリズムを持つ。しかしL1とは違ってここでは「Write-Back」「Write-Allocate」ポリシーを使う。小さく小分けされたL2メモリブロックは64~128KBの空間を持つ。\nL2キャッシュがCoherentすることにより、それぞれ違うWavefrontの間の同期化またはアトミック操作（Atomic Operation）が実行できるように適合な場になった。もちろんWavefrontの中のみならLDSだけでアトミック操作することが可能である。しかし違うWavefrontの間に同期化をすべきならL2キャッシュを使わなければならない。L2スライスは1サイクル、1キャッシュラインに16個のアトミック操作をする事ができる。\n理論上ではL1データは作業グループの中でのメモリ一貫性を保つ。Wavefrontが開放される時、または同期化のためのバリアーが解かれた時データがL2にかかれてWavefront間のL2メモリ一貫性が維持される。\nまたこのキャッシュ構造はx86のマイクロプロセッサーと互換するようにデザインされた。GCN仮想メモリシステムはx86アドレス空間のための基本ページ単位である4KBのページをサポートしている。またキャッシュラインが64Bytesであることもx86のプロセッサーと互換するためだそうだ。\nメモリコントローラーは64-Bits長さで2つの独立したGDDR5またはDDR3の32-Bitsメモリチャンネルで構成されている。\nProgramming Model p11）GCNの新しいISAはHSAを基にしている。HSAとはハードウェアに拘らないアーキテクチャとして（決まった仕様はあるので完全独立ではない）CPUとGPUがコミュニケーションする仕様だ。HSAはHSAIL（Intermediate Language）というバーチャルISAを使って最終的にはHWの機械語にコンパイルするようにしている。[12]\nSystem Architecture GCNは双方向のDMAエンジンを搭載し、PCI Express™ 3.0を使ってデータを双方向に転送することが出来る。またGCNはIOMMUを搭載し、x86のアドレスをGPUへマッピングすること簡単に出来る。ということはGCNのDMAエンジンはGPUとCPUのメモリページへの接近が追加オーバーヘッドなしで行われる。\nGCNのCommand Processorはドライバーから高級言語のAPIを読み取り、各パイプラインへマッピングする役割を持っている。GCNでは主に2つのパイプラインで構成されている。一つはACEと呼ばれるもので、Compute Shaderを管理している。Graphics Command Processorは従来のシェーダーと固定関数を管理する。ACEとGCPは一緒に各シェーダーステージのためのCommand Streamを持ち、GCN仕様のHWでマルチタスキングを行う。\nそのマルチタスキングのためにGCNでは仮想メモリが実装された。ということでGPUのVRAMの中で複数のアプリケーションのメモリが安全に共存できる。\nACEsはCompute Shaderに対してスケジューリングとリソースの割当を担当する。各ACEはキャッシュまたはメモリからコマンとを持ってきて、スケジューリングのためのTask queueを形成する。各タスク（Task）は優先順位を持っており、ドライバーからそれらを制御している。\n各サイクルでACEは作業グループと一つのWavefrontを作り依存性が無い限り無作為に動作する。\nまたACEsは普通はそれぞれ独立に動くが、64KB~128KBのGDS、メモリまたはキャッシュ接近によって同期化されることがある。それにより各ACEsはTask Graphを形成し、お互いに依存性を持つようになる。なので実際にはACEsはグラフィックスパイプラインの特定ステージ、それとも他のACEに依存されるかするようになり、途中で止まったり違うTask queueの依存性を持たないACEが動いたりする。\nGraphics Architecture Graphics Command Processorは従来のグラフィックスパイプラインを構想している。GCNのピクセルパイプラインはスクリーン空間を分割して独立したタイルとしてレンダリングする。各ラスタライザは1サイクルに一つの三角形を分析し、最大16ピクセルを生み出す。\nまたGCNでは各グラフィックパイプラインは並列に動く。これはACEsと同じであるし、すなわち依存性も生まれる。\n参照 AMD GRAPHICS CORES NEXT White Paper\nGS-4106 The AMD GCN Architecture - A Crash Course, by Layla Mah\n[3] Cache Associativity\n[4] Memory Bank\n[5] Address Generation Unit\n[6] Multiply-accumulate operation\n[7] Sum of absolute difference\n[8] Cache_(Computing) Writing policies\n[9] Interaction Policies with Main Memory\n[10] In CUDA, what is memory coalescing, and how is it achieved?\n[11] Translation Lookaside Buffer\n[12] AMD GPUとモバイルGPUにで同じプログラムを走らせるHSA構想\n","wordCount":"8668","inLanguage":"en","datePublished":"2020-06-19T12:16:09+09:00","dateModified":"2020-06-23T08:42:00+09:00","author":{"@type":"Person","name":"Jongmin Yun, Neu."},"mainEntityOfPage":{"@type":"WebPage","@id":"https://liliilli.github.io/posts/gcn_architecture_crash/"},"publisher":{"@type":"Organization","name":"neuromantic","logo":{"@type":"ImageObject","url":"https://liliilli.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://liliilli.github.io accesskey=h title="neuromantic (Alt + H)">neuromantic</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://liliilli.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://liliilli.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://liliilli.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://liliilli.github.io/series/ title=Series><span>Series</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://liliilli.github.io>Home</a>&nbsp;»&nbsp;<a href=https://liliilli.github.io/posts/>Posts</a></div><h1 class=post-title>AMD GCNアーキテクチャ文書を読んでメモ</h1><div class=post-meta>2020, June 19&nbsp;·&nbsp;Jongmin Yun, Neu.</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#%e7%94%a8%e8%aa%9e aria-label=用語>用語</a></li><li><a href=#%e6%9c%ac%e6%96%87-amd-graphics-cores-next-white-paper aria-label="本文 (AMD GRAPHICS CORES NEXT White Paper)">本文 (AMD GRAPHICS CORES NEXT White Paper)</a><ul><li><a href=#compute-unit-overview aria-label="Compute Unit Overview">Compute Unit Overview</a></li><li><a href=#cu-front-end aria-label="CU Front-End">CU Front-End</a></li><li><a href=#scalar-execution-and-control-flow aria-label="Scalar Execution and Control Flow">Scalar Execution and Control Flow</a></li><li><a href=#vector-execution aria-label="Vector Execution">Vector Execution</a></li><li><a href=#vector-registers aria-label="Vector Registers">Vector Registers</a></li><li><a href=#vector-alus aria-label="Vector ALUs">Vector ALUs</a></li><li><a href=#local-data-share--atomics aria-label="Local Data Share &amp;amp; Atomics">Local Data Share & Atomics</a></li><li><a href=#export aria-label=Export>Export</a></li><li><a href=#vertor-memory aria-label="Vertor Memory">Vertor Memory</a></li><li><a href=#l2-cachecoherency-and-memory aria-label="L2 Cache、Coherency and Memory">L2 Cache、Coherency and Memory</a></li><li><a href=#programming-model aria-label="Programming Model">Programming Model</a></li><li><a href=#system-architecture aria-label="System Architecture">System Architecture</a></li><li><a href=#graphics-architecture aria-label="Graphics Architecture">Graphics Architecture</a></li></ul></li><li><a href=#%e5%8f%82%e7%85%a7 aria-label=参照>参照</a></li></ul></div></details></div><div class=post-content><h2 id=用語>用語<a hidden class=anchor aria-hidden=true href=#用語>#</a></h2><table><thead><tr><th>略語</th><th>説明</th></tr></thead><tbody><tr><td>VS</td><td>Vertex Shader</td></tr><tr><td>PS</td><td>Pixel Shader (Fragment Shader)</td></tr><tr><td>VLIW</td><td>Very Long Instruction Word</td></tr><tr><td>FLOPS</td><td>FLoating point Operations Per Second</td></tr><tr><td>GCN</td><td>Graphics Core Next</td></tr><tr><td>CU</td><td>Compute Unit</td></tr><tr><td>EU</td><td>Export Unit</td></tr><tr><td>ISA</td><td>Instruction Set Architecture</td></tr><tr><td>SIMD</td><td>Single Instruction Multiple Data</td></tr><tr><td>ALU</td><td>Arithmetic Logic Unit</td></tr><tr><td>AGU</td><td>Address Generation Unit</td></tr><tr><td>SALU</td><td>Scalar Arithmetic Logic Unit</td></tr><tr><td>VALU</td><td>Vector Arithmetic Logic Unit</td></tr><tr><td>APU</td><td>Accelated Processing Unit</td></tr><tr><td>PC</td><td>Program Counter</td></tr><tr><td>IB</td><td>Instruction Buffer</td></tr><tr><td>LRU</td><td>Least Recently Used</td></tr><tr><td>VGRP</td><td>Vector General Purpose Register</td></tr><tr><td>LDS</td><td>Local Data Share</td></tr><tr><td>GDS</td><td>Global Data Share</td></tr><tr><td>TMU</td><td>Texture Mapping Unit</td></tr><tr><td>TLB</td><td>Translation Lookaside Buffer</td></tr><tr><td>HSA</td><td>Heterogeneous System Architecture</td></tr><tr><td>DMA</td><td>Direct Memory Access</td></tr><tr><td>IOMMU</td><td>I/O MMU (I/O Memory Management Unit)</td></tr><tr><td>ACE</td><td>Asynchronous Compute Engines</td></tr></tbody></table><h2 id=本文-amd-graphics-cores-next-white-paper>本文 (AMD GRAPHICS CORES NEXT White Paper)<a hidden class=anchor aria-hidden=true href=#本文-amd-graphics-cores-next-white-paper>#</a></h2><p>p2）最初は完全な固定関数として使うようにデザインされたが、時間が経ってVSとPSの登場、そしてAMDでは並列処理を効率化させるためVLIW5とVLIW4構造のデザインを開発し性能を上げてきた。</p><p>これで2013年まで出た最高級グラボのTFLOPSは4TFLOPS（テラFLOPS）を超えて、モバイルも1TFLOPSを超えるようになる。</p><p>VLIW4デザインから一新されたGCNはCUのデザインを変えて性能を向上をした。</p><h3 id=compute-unit-overview>Compute Unit Overview<a hidden class=anchor aria-hidden=true href=#compute-unit-overview>#</a></h3><p>p3）CUはGCNアーキテクチャでの基本的な演算ブロックだ。以前に使っていたISAも新しくされて、コンパイラそして開発者にもわかりやすい形となり、性能の安定性を確保している。</p><p>GCN以前のVLIWシリーズのシェーダー配列は複数のSIMDエンジンとして構成され、また各SIMDエンジンは16個のALUで構成されていた。各ALUは4、5個の独立した命令をVLIWに入れてまとめた形で処理することが出来た。（前はVLIW-4、後はVLIW-5）各SIMDエンジンはWavefrontという、64個の命令処理ができるもの（作業スレッド）を持ち、同時に1個のWavefrontを実行することが出来る。このデザインは特定したパイプラインでは高効率で動くが、ピクセルのフォーマットが多様化されて、またパイプラインが複雑になるにつれそれぞれ独立されて並列に実行できる命令をVLIWに組むことが難しくなって効率を上げにくくなった。</p><p>GCNでは各CUが4個の分離された頂点処理のためのSIMDを持って、各SIMDは同一な命令を処理する16個の作業スレッドを持っている。ただ、前のデザインみたいにまとまって1個のWavefrontになるのではなく、それぞれ別のWavefrontになれる。なのでもっと並列化が出来る。</p><p>効率化のためにGCNの各SIMDたちは<code>private</code>と<code>shared</code>のリソースを持ったり、共有している。命令バッファリング（Instruction Buffering）、VALUとレジスタなどはPrivateとして各SIMDに内蔵されている。Front-End、分岐ユニット、データキャッシュはSIMDの間で共有されている。</p><p>p4）GCNのCUの画像があるのでよく見ること。</p><p>またGCNで改善されたものは、メモリのCoherent Cachingがサポートされたことだ。GCNが登場づするまでGPUはメモリのCoherent（一貫性）を管理しない（すなわち外部メモリ変更による更新をしない）読み取り専用のキャッシュに依存しなければならなかった。なのでGPU中で複数のコアがやり取りをするためには、プログラマまたはコンパイラが明示的に同期化をしなければならなかった。デザイン的には簡単になるが、共有しているデータの同期化による性能低下があったのである。GCNは最初から汎用データがコア間共有されながら処理されることを念頭に置きながらデザインされた。そのためのCache Coherency ProtocolはGPUのL2キャッシュを通してデータを更新するようにし、性能向上と電力消費量の低下をした。</p><p>Coherencyと同時にGCNは仮想メモリも導入した。この仮想メモリはx86アーキテクチャをサポートする。これでCPUとGPUの間でデータを共有することが簡略化され、そして一つのポインターアドレスでCPUとGPUが参照出来るようになったそうだ。これでAMDのAPUでも効率の向上をしたらしい。</p><h3 id=cu-front-end>CU Front-End<a hidden class=anchor aria-hidden=true href=#cu-front-end>#</a></h3><p>p5）GCNの各SIMDは40-bitのPCと、10Wavefront分のIBを持つ。というとCUは4個のSIMDを持つのでIBだけで40Wavefrontsを持つことになる。そしてGCNは32個のCUを持つため、最終的には同時に81,920個の作業スレッドが働くことになる。</p><p>4個までのCUが一つの組になり、32KBの4-way associativeのL1命令キャッシュとL2キャッシュを共有している。<em>[3]を見ること</em> キャッシュラインはx86と同じく64Bytesで、64bitsの命令を8個収めることが出来る。キャッシュが全部埋まったら、LRUによって新しい命令が入ることになる。</p><p>L1の命令キャッシュは4個のBankを持ち[4]、4個のCUに対して32Bytesの命令読出し（Fetch）を維持することが出来る。ただ、命令読出しは世代（age）、スケジューリングの優先順位、WaveのIBの活用によってSIMDたちの中で無作為にされる。</p><p>命令がWavefrontのバッファたちの中で発行されると、CUはRound-robin方式で4個のSIMDから一つを選び、10個のWavefrontから5個までの命令をEUへ実行するようにする。ただ<code>NOP</code>のような特殊な命令は他のユニットに任せることなくWavefrontから直接命令処理をする。また、CUはバリア命令を追跡するため16個のバッファリングを維持することができ、これによってWavefrontをSynchronizeさせる。</p><p>CUの末端部（Front-end）は「分岐（Branch）、SALU、VALU、スカラメモリ、ベクトルメモリ、そしてローカルデータシェアー、グローバルデータシェアー」の命令を処理する。しかし命令実行パイプラインに多くのSIMDが取り付くことを防ぐため、SIMDごとに同時に各タイプの一つの命令しか発行できないようになっている。また、命令順に実行するようにするため、各命令は違うWavefrontから発行されるようになっている。</p><p>CUは1サイクルに5個までの命令を、2つのレジスタファイル（Register File）を使って、6個までのベクトル演算装置とスカラ演算装置へ実行できる。VALUは汎用目的のグラフィック、またはコンピューター処理のために適合していて、SALUは分岐処理に適合している。</p><h3 id=scalar-execution-and-control-flow>Scalar Execution and Control Flow<a hidden class=anchor aria-hidden=true href=#scalar-execution-and-control-flow>#</a></h3><p>GCNで新しく実装されたスカラ（Scalar）パイプラインは、性能と電力効率で必須的な存在となっている。特に分岐処理をすることによって、GPUで分岐しょりをすることによる遅延などを防ぎ、性能低下をある程度防止する。</p><p>各CUは8KBのスカラレジスタファイル（Scalar Register File）を持ち、各SIMDが使えるために512個のブロックとして分かれている。また、スカラレジスタはSIMDの10個のWavefrontで共有される。Wavefrontはシステムの状態を保持する一部分を除き、112個のレジスタが割当できる。これをユーザーレジスタ（User Register）という。</p><p>レジスタは普段は32-bitsの値を保持できるが、連続で使ったら64-bitsまでの値を保持できる。例えば比較分岐をする時、比較した際の結果ビットをwavefrontの64個分更新するためには64-bitsのレジスタ（2個分）に必要となる。</p><p>1つ目でスカラパイプラインは16-bitsのオフセットを使って分岐（Conditional Branch）をハンドルしている。また、インターラプトと特定タイプの同期化をする時にも使われている。インターラプトはブレークポイントを貼ってデバッグをする際に使える新しい機能だ。</p><p>p6）2つ目ではAGUの役割<code>[5]</code>も果たしている。GCNのALUは64-bitsの長さを持つが、これで分岐処理によるジャンプ、関数呼び出しとリターンがもっとしやすくなっている。AGUによって移動する命令アドレスはPCで切り替わるかそれに値する処理がされている。</p><p>また分岐予測もSALUによって管理される。</p><p>スカラのL1キャッシュは読み取り専用だ。SALUが使われている所って大体分岐処理であるため、メモリに何かを書く状況がないためだ。このL1キャッシュは命令L1メモリキャッシュとほぼ構造が同じで、16KBのキャッシュは同様に4-way associativeであって、LRUアルゴリズムと64Bytesのラインを持つ。また4個のCUによって共有されて、L2キャッシュがあることも同じだ。そして各CUで1サイクルに16BytesのThroughputを持つ。</p><h3 id=vector-execution>Vector Execution<a hidden class=anchor aria-hidden=true href=#vector-execution>#</a></h3><p>既存のVLIWは一つのSIMDを持ち、その中に独立で演算される命令が組み込まれて実行される仕組みになっている。しかしこの構造はコンパイラがどのぐらいコードから生み出される命令を並行にばら撒いて実行させるようにするかによって性能が大きく違うことと、コード自体が並列化されにくいとしたら絶対的に性能が落ちることになる短所がある。</p><p>GDNアーキテクチャはWavefrontから予測できない並列化を避けるようにし、ちょうど良いぐらいの並列化をドライバーなどがやるようにして、性能の安定性を追求する。こうすることで汎用目的の処理でも性能が劣ることがあんまりなくなった。</p><h3 id=vector-registers>Vector Registers<a hidden class=anchor aria-hidden=true href=#vector-registers>#</a></h3><p>ベクトル演算のためのレジスタも4つの独立されたブロックに分かれている。以前のVLIW構造では一つのSIMDにあらゆる命令がまざって入るため、どでかく効率が悪いレジスタにしなければならなかった。</p><p>VGRPsは32-bits長さの64個のレーンを持つ。隣接したVGRPsは64ビットまたは128ビットに相当する値を構成されるために使えることもある。各SIMDはVGRPsのために64KBのパーティションを提供しているので、CU1個のVGRPsの数は同一である。（256個のVGRPs組が存在して、一つは32-bits＊64＝256Bytes？）</p><h3 id=vector-alus>Vector ALUs<a hidden class=anchor aria-hidden=true href=#vector-alus>#</a></h3><p>p7）各SIMDは16個のレーンで構成され、IEEE-754単精度浮動小数点数と倍精度浮動小数点数を支援する。また、性能低下の無いdenormals（アンダーフローされる浮動小数点の数前の数）などもサポートする。SIMDの各レーンは24-bitの整数演算、また単精度の積和演算・融合積和演算<code>[6]</code>（fused multiply-add）ができる。積和演算は<code>MAD</code>のような形として、<code>a := b * c + a</code>になる。融合積和とは、<code>b * c</code>をする時浮動小数点の値を丸めずに1命令で行い誤差をへらすことだ。</p><p>24-bitsの整数のMAD演算は作業グループの中でアドレスを演算する時に有用に使われる。一つのSIMDの64個の作業スレッドがVALUの演算を行うには4 Cyclesがかかる。</p><p>GCNは<code>SAD</code>と<code>quad-SAD</code>を追加し<code>[7]</code>、映像または画像処理の性能を向上しようとした。SADは画像がどれだけ似ているかを検出する時に使われるアルゴリズムで、画像の中で異なるブロックの中の互いのピクセルの絶対差を求め最後に全部合わせて似ているかの指標として使う。またRGBA 8-Bitsの色が入った画像でもSADが出来るようにquad-SADを追加した。</p><p>これを使ってCUはクロックごとに256個のピクセルの処理ができた。こういったものはビデオ検索、または動作認識などに使われるそうだ。</p><p>倍精度と32-Bitsの整数処理は処理効率が劣る。倍精度浮動小数点の場合、単精度より1/2から1/16まで性能が落ちる可能性がある。またドライバーなどのサポートによって性能が違うかもしれない。</p><h3 id=local-data-share--atomics>Local Data Share & Atomics<a hidden class=anchor aria-hidden=true href=#local-data-share--atomics>#</a></h3><p>LDSというメモリ領域はグラフィックレンダリングでの補完または作業グループ（Work-group）の同期化のためにほぼ第3のRegister Fileとして扱わなければならない。（重要）GCNのLDSは16または32個のBanksを持って、64KBに拡張された。各Bankは32-Bits長さのエントリーが512個並んでいる。</p><p>LDSの用途としてレンダリングの方ではテクスチャーデータの補完などに使われる。その時に同時データ接近による衝突は起こらない。Compute Shaderの場合にはWork-Groupsの中で共有されたデータなどを読み込んだり書き込んだりする時にLDSが使われる。これによってデータの接近によるキャッシュの汚染が避けるようになった。</p><h3 id=export>Export<a hidden class=anchor aria-hidden=true href=#export>#</a></h3><p>EUはCUからGDS（Global Data Share）そして固定関数のグラフィックHWへの窓口だ。CUで演算が終わった時、一般的に結果はグラフィックパイプラインのほかのユニットへ転送される。EUはプログラミング可能なステージから得た結果をテセレーションまたはRasterization、Back-endなどに書き込む役割をする。</p><p>GDSはLDSとは基本的には同じものだが、全体CUが共有しているのですべてのWavefrontの間の同期化を制御する。</p><h3 id=vertor-memory>Vertor Memory<a hidden class=anchor aria-hidden=true href=#vertor-memory>#</a></h3><p>各CUの各SIMDsは1クロックに128個の単精度浮動小数点数の演算が出来る。既存のVLIW-4からGCNに移行してキャッシュの構造で一番変わったのはグラフィック描画に特化されたデザインから汎用レンダリングまたはx86のプロセッサーと互換ができるようプログラミングな構造になったことだ。代表的なものがCUで、GCN全般のシステムまで拡張している。</p><p>p9）Figure 5を見ること。</p><p>上にもあったが、L1データキャッシュは16KB、4-way associative、64Bytesライン、そしてLRUアルゴリズムを持つ。またL2データそして他のキャッシュとのデータと同じ（Coherent）データ内容を持つ。</p><p>データL1（L1D）はDirtyマスクがついた「Write-through」<code>[8]</code>（メモリとキャッシュへの書き込みが同時に終わる）そして「Write-allocate」（Write-missの際に下のデータブロックが上のキャッシュにOverwrite）を採択している。~（＋ということは実際にはWrite-throughではなく、Write-backなのでは…？）~<code>[9]</code>64Wavefrontに該当するキャッシュラインは命令が終わるとL2へOverwriteされる。またL1のキャッシュラインがDirtyかではないかによってL2へ放出されるかないかが分かれる。</p><p>AGU（Address Generation Unit）が連続したアドレス（0x0, 0x4, 0x8…）を計算したらデータL1のキャッシュタグ（Cache-Tag）をたどる。それでCache hitが発生したら64Bytesのラインを全部読み取る。もしデータがすべて連続されていて一つのキャッシュラインに収まることが出来たら（With fully coalesced requests,）実際使ってるWavefrontは1/4ぐらいになる。読まれたキャッシュラインはvGRPsかLDSに保存される。</p><p>L1データへの書き込みはちょっと複雑で、データ自体が適切なフォーマットに変換しなければならないし、また書き込むアドレスもL1キャッシュへのHit、L2キャッシュへまで書き込むために癒合（Coalesced）される必要があるそうだ。もしCache missが発生したらL2それともそれに準ずるメモリでブロックを探す。</p><p>効率を上げるためにグラフィックレンダリングではある構造を再使用（？）している。まずAGUは1サイクルに4個のテクスチャアドレスを受け取り、nearest neighborsで16個のサンプリングアドレスを返す。このサンプリングアドレスがL1データに接近し読み取ったデータをTMUから圧縮開放する。そしてフィルターによってフォーマットに合わせた4個の補完されたテクセルがベクトルのRegister Fileに保存される。</p><h3 id=l2-cachecoherency-and-memory>L2 Cache、Coherency and Memory<a hidden class=anchor aria-hidden=true href=#l2-cachecoherency-and-memory>#</a></h3><p>p10）L2キャッシュはGCNGPUのcoherencyを維持する中核だ。L2キャッシュはCUまたはCUたちの間で共有されているL1命令とデータ、そしてスカラキャッシュのbackstop（補助？盗み取り？）役をしている。L2キャッシュはいくつかのブロックなどに分離されて、CUからCrossbarを通してメモリへアクセスされるようになっている。</p><blockquote><p>Figure 6を見ること。</p></blockquote><p>L1と同様にL2も仮想アドレスをサポートしているのでTLBは要らない。（なんかVirtualだとしたらPhysicalに変換するためにTLBが要るかもと思ったらそうでもなかった…）<code>[11]</code> そしてL2は16-way associativeでL1と同じく64Bytesキャッシュライン、LRUアルゴリズムを持つ。しかしL1とは違ってここでは「Write-Back」「Write-Allocate」ポリシーを使う。小さく小分けされたL2メモリブロックは64~128KBの空間を持つ。</p><p>L2キャッシュがCoherentすることにより、それぞれ違うWavefrontの間の同期化またはアトミック操作（Atomic Operation）が実行できるように適合な場になった。もちろんWavefrontの中のみならLDSだけでアトミック操作することが可能である。しかし違うWavefrontの間に同期化をすべきならL2キャッシュを使わなければならない。L2スライスは1サイクル、1キャッシュラインに16個のアトミック操作をする事ができる。</p><p>理論上ではL1データは作業グループの中でのメモリ一貫性を保つ。Wavefrontが開放される時、または同期化のためのバリアーが解かれた時データがL2にかかれてWavefront間のL2メモリ一貫性が維持される。</p><p>またこのキャッシュ構造はx86のマイクロプロセッサーと互換するようにデザインされた。GCN仮想メモリシステムはx86アドレス空間のための基本ページ単位である4KBのページをサポートしている。またキャッシュラインが64Bytesであることもx86のプロセッサーと互換するためだそうだ。</p><p>メモリコントローラーは64-Bits長さで2つの独立したGDDR5またはDDR3の32-Bitsメモリチャンネルで構成されている。</p><h3 id=programming-model>Programming Model<a hidden class=anchor aria-hidden=true href=#programming-model>#</a></h3><p>p11）GCNの新しいISAはHSAを基にしている。HSAとはハードウェアに拘らないアーキテクチャとして（決まった仕様はあるので完全独立ではない）CPUとGPUがコミュニケーションする仕様だ。HSAはHSAIL（Intermediate Language）というバーチャルISAを使って最終的にはHWの機械語にコンパイルするようにしている。<code>[12]</code></p><h3 id=system-architecture>System Architecture<a hidden class=anchor aria-hidden=true href=#system-architecture>#</a></h3><p>GCNは双方向のDMAエンジンを搭載し、PCI Express™ 3.0を使ってデータを双方向に転送することが出来る。またGCNはIOMMUを搭載し、x86のアドレスをGPUへマッピングすること簡単に出来る。ということはGCNのDMAエンジンはGPUとCPUのメモリページへの接近が追加オーバーヘッドなしで行われる。</p><p>GCNのCommand Processorはドライバーから高級言語のAPIを読み取り、各パイプラインへマッピングする役割を持っている。GCNでは主に2つのパイプラインで構成されている。一つはACEと呼ばれるもので、Compute Shaderを管理している。Graphics Command Processorは従来のシェーダーと固定関数を管理する。ACEとGCPは一緒に各シェーダーステージのためのCommand Streamを持ち、GCN仕様のHWでマルチタスキングを行う。</p><p>そのマルチタスキングのためにGCNでは仮想メモリが実装された。ということでGPUのVRAMの中で複数のアプリケーションのメモリが安全に共存できる。</p><p>ACEsはCompute Shaderに対してスケジューリングとリソースの割当を担当する。各ACEはキャッシュまたはメモリからコマンとを持ってきて、スケジューリングのためのTask queueを形成する。各タスク（Task）は優先順位を持っており、ドライバーからそれらを制御している。</p><p>各サイクルでACEは作業グループと一つのWavefrontを作り依存性が無い限り無作為に動作する。</p><p>またACEsは普通はそれぞれ独立に動くが、64KB~128KBのGDS、メモリまたはキャッシュ接近によって同期化されることがある。それにより各ACEsはTask Graphを形成し、お互いに依存性を持つようになる。なので実際にはACEsはグラフィックスパイプラインの特定ステージ、それとも他のACEに依存されるかするようになり、途中で止まったり違うTask queueの依存性を持たないACEが動いたりする。</p><h3 id=graphics-architecture>Graphics Architecture<a hidden class=anchor aria-hidden=true href=#graphics-architecture>#</a></h3><p>Graphics Command Processorは従来のグラフィックスパイプラインを構想している。GCNのピクセルパイプラインはスクリーン空間を分割して独立したタイルとしてレンダリングする。各ラスタライザは1サイクルに一つの三角形を分析し、最大16ピクセルを生み出す。</p><p>またGCNでは各グラフィックパイプラインは並列に動く。これはACEsと同じであるし、すなわち依存性も生まれる。</p><h2 id=参照>参照<a hidden class=anchor aria-hidden=true href=#参照>#</a></h2><p><a href=https://www.techpowerup.com/gpu-specs/docs/amd-gcn1-architecture.pdf>AMD GRAPHICS CORES NEXT White Paper</a></p><p><a href=https://www.slideshare.net/DevCentralAMD/gs4106-the-amd-gcn-architecture-a-crash-course-by-layla-mah>GS-4106 The AMD GCN Architecture - A Crash Course, by Layla Mah</a></p><p><a href=http://csillustrated.berkeley.edu/PDFs/handouts/cache-3-associativity-handout.pdf>[3] Cache Associativity</a></p><p><a href=https://en.wikipedia.org/wiki/Memory_bank>[4] Memory Bank</a></p><p><a href=https://en.wikipedia.org/wiki/Address_generation_unit>[5] Address Generation Unit</a></p><p><a href=%5Bhttps://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation#Fused_multiply%E2%80%93add%5D(https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation#Fused_multiply%E2%80%93add)>[6] Multiply-accumulate operation</a></p><p><a href="https://www.google.com/search?q=sum+of+absolute+difference&oq=sum+of+absol&aqs=chrome.0.0j69i57j0l6.2572j0j4&sourceid=chrome&ie=UTF-8">[7] Sum of absolute difference</a></p><p><a href=https://en.wikipedia.org/wiki/Cache_(computing)>[8] Cache_(Computing) Writing policies</a></p><p><a href=http://web.cs.iastate.edu/~prabhu/Tutorial/CACHE/interac.html>[9] Interaction Policies with Main Memory</a></p><p><a href=https://stackoverflow.com/questions/5041328/in-cuda-what-is-memory-coalescing-and-how-is-it-achieved>[10] In CUDA, what is memory coalescing, and how is it achieved?</a></p><p><a href=https://en.wikipedia.org/wiki/Translation_lookaside_buffer>[11] Translation Lookaside Buffer</a></p><p><a href=https://pc.watch.impress.co.jp/docs/column/kaigai/547768.html>[12] AMD GPUとモバイルGPUにで同じプログラムを走らせるHSA構想</a></p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://liliilli.github.io/posts/rust_winapi_memo/><span class=title>« Prev Page</span><br><span>Rust＋Winapiで窓を生成してみた</span></a>
<a class=next href=https://liliilli.github.io/posts/week25_2020/><span class=title>Next Page »</span><br><span>最近簡単に読んだポスト</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share AMD GCNアーキテクチャ文書を読んでメモ on twitter" href="https://twitter.com/intent/tweet/?text=AMD%20GCN%e3%82%a2%e3%83%bc%e3%82%ad%e3%83%86%e3%82%af%e3%83%81%e3%83%a3%e6%96%87%e6%9b%b8%e3%82%92%e8%aa%ad%e3%82%93%e3%81%a7%e3%83%a1%e3%83%a2&url=https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share AMD GCNアーキテクチャ文書を読んでメモ on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f&title=AMD%20GCN%e3%82%a2%e3%83%bc%e3%82%ad%e3%83%86%e3%82%af%e3%83%81%e3%83%a3%e6%96%87%e6%9b%b8%e3%82%92%e8%aa%ad%e3%82%93%e3%81%a7%e3%83%a1%e3%83%a2&summary=AMD%20GCN%e3%82%a2%e3%83%bc%e3%82%ad%e3%83%86%e3%82%af%e3%83%81%e3%83%a3%e6%96%87%e6%9b%b8%e3%82%92%e8%aa%ad%e3%82%93%e3%81%a7%e3%83%a1%e3%83%a2&source=https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share AMD GCNアーキテクチャ文書を読んでメモ on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f&title=AMD%20GCN%e3%82%a2%e3%83%bc%e3%82%ad%e3%83%86%e3%82%af%e3%83%81%e3%83%a3%e6%96%87%e6%9b%b8%e3%82%92%e8%aa%ad%e3%82%93%e3%81%a7%e3%83%a1%e3%83%a2"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share AMD GCNアーキテクチャ文書を読んでメモ on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share AMD GCNアーキテクチャ文書を読んでメモ on whatsapp" href="https://api.whatsapp.com/send?text=AMD%20GCN%e3%82%a2%e3%83%bc%e3%82%ad%e3%83%86%e3%82%af%e3%83%81%e3%83%a3%e6%96%87%e6%9b%b8%e3%82%92%e8%aa%ad%e3%82%93%e3%81%a7%e3%83%a1%e3%83%a2%20-%20https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share AMD GCNアーキテクチャ文書を読んでメモ on telegram" href="https://telegram.me/share/url?text=AMD%20GCN%e3%82%a2%e3%83%bc%e3%82%ad%e3%83%86%e3%82%af%e3%83%81%e3%83%a3%e6%96%87%e6%9b%b8%e3%82%92%e8%aa%ad%e3%82%93%e3%81%a7%e3%83%a1%e3%83%a2&url=https%3a%2f%2fliliilli.github.io%2fposts%2fgcn_architecture_crash%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>Copyright © 2008–2019, Steve Francia and the Hugo Authors; all rights reserved.</span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>window.onload=function(){localStorage.getItem("menu-scroll-position")&&(document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position"))};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft)}document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script><script>document.querySelectorAll('pre > code').forEach(b=>{const c=b.parentNode.parentNode,a=document.createElement('button');a.classList.add('copy-code'),a.innerText='copy';function d(){a.innerText='copied!',setTimeout(()=>{a.innerText='copy'},2e3)}a.addEventListener('click',e=>{if('clipboard'in navigator){navigator.clipboard.writeText(b.textContent),d();return}const a=document.createRange();a.selectNodeContents(b);const c=window.getSelection();c.removeAllRanges(),c.addRange(a);try{document.execCommand('copy'),d()}catch(a){}c.removeRange(a)}),c.classList.contains("highlight")?c.appendChild(a):c.parentNode.firstChild==c||(b.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?b.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(a):b.parentNode.appendChild(a))})</script></body></html>